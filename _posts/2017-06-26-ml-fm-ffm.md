---
layout: post
comments: true
title: "ML Notes: Factorization Machine & Field-aware Factorization Machine"
date: 2017-06-26
---

## Introduction

This post is to summarize FM & FFM:

- **Factorization Machine (FM):** Rendle (ICDM, 2010)
- **Field-aware Factorization Machine (FFM):** Juan et al. (RecSys, 2016)


## Traditional Polynomial Regression

<div style="text-align:center">
<img src="/images/polynomial_eqt.png" alt="Drawing" style="width: 400px;"/>
</div>

- $$n$$: number of features
- Number of unknown weights: $$O(n^2)$$,

$$
\binom{n}{2} = \frac{n (n - 1)}{2}
$$

- Since the data is usually sparse, especially for categorical features, the model performance is expected to be poor.
- To improve the model performance, we would like to use “shared” weights to reduce the number of weights.


## FM

- Rendle (2010) uses “shared” latent factor, $$v_i$$, of feature $$x_i$$ in the interactions of $$x_i x_j$$ and $$x_i x_{j-}$$.

<div style="text-align:center">
<img src="/images/fm_eqt.png" alt="Drawing" style="width: 400px;"/>
</div>

- $$n$$: number of features
- $$v_i$$ is latent factor of feature $$x_i$$, with latent factor length $$k$$
- Originally, the complexity (or approximately the number of unknown parameters) of FM seems to be $$O(k n^2)$$. 
- However, with the following identity equation which is like the **Kernel Trick**:

<div style="text-align:center">
<img src="/images/fm_kernel_trick.png" alt="Drawing" style="width: 400px;"/>
</div>

the real complexity of FM is about $$O(kn)$$.


## FFM

- Juan et al. (2016) further extends FM to consider “field-aware interaction effect”.
- That is, uses “different” latent factors, $$v_{i, f_j}$$ and $$v_{i, f_j-}$$, of feature $$x_i$$ in the interactions of $$x_i x_j$$ and $$x_i x

<div style="text-align:center">
<img src="/images/ffm_eqt.png" alt="Drawing" style="width: 400px;"/>
</div>

- Suppose $$n$$: number of features, which have $$f$$ fields.
- $$v_{i, f_j}$$ is latent factor of feature $$x_i$$ for the interaction with $$x_j$$ belonging to field $$f_j$$, with latent factor length $$k$$.
- For the numbers of 2nd-order polynomial weights, 
  * FFM: $$nfk \gg$$ FM: $$nk$$
- The complexity of FFM is about $$O(kn^2)$$.
  * of course _larger than that of FM_, that's why FFM would perform better than FM and is consistent with the **No Free Lunch Theorem**. 
- General model complexity comparison:
  * $$\bar n$$: average “effected” feature numbers; that is, average non-zero features per instance.

<div style="text-align:center">
<img src="/images/ffm_complexity_compare.png" alt="Drawing" style="width: 300px;"/>
</div>


## References

- FM paper: Rendle (ICDM, 2010): http://libfm.org/  
- FFM paper: Juan et al. (RecSys, 2016): http://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf
- FFM GitHub: https://github.com/guestwalk/libffm
- FFM website: LibFFM: https://www.csie.ntu.edu.tw/~cjlin/libffm/
- Blog post: http://tech.meituan.com/deep-understanding-of-ffm-principles-and-practices.html
